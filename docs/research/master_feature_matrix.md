# Master Feature Matrix (Agentic Coding Repos)

**Snapshot date:** 2026-01-16

This matrix is a condensed extraction from the per-repo dossiers in `repo_dossiers/`.

| Repo | Primary language | Interfaces | Orchestration primitive | State/persistence | HITL controls | Sandboxing/safety | Observability | Evaluation | Extensibility |
|--- | --- | --- | --- | --- | --- | --- | --- | --- | ---|
| All-Hands-AI/OpenHands | Python | CLI, SDK (Python + REST), Cloud, IDE integrations via ACP | SDK-driven agent runs; supports multi-agent refactors and maintenance via orchestration at the app layer; skills/microagents architecture for reusable behaviors. | CLI/IDE integration stores settings (and supports resuming conversations); SDK + agent server imply durable state can be implemented externally; benchmarks repo indicates standardized evaluation pipelines. | IDE integration and CLI imply interactive workflows; ACP enables editors to drive agent sessions; approval gates are implementation-dependent. | Docs emphasize sandboxed runtime you control (Docker/Kubernetes) and configuration reuse; treat external connectivity as governed via tool layer + runtime policy. | Evaluation harness plus unit tests; production agent server suggests logs/metrics integration via deployment platform. | Dedicated benchmarks repo (SWE-Bench, GAIA, Commit0, OpenAgentSafety). | SDK exposes custom tools and custom behaviors; skills/microagents architecture for reusable patterns. |
| microsoft/agent-framework | .NET | SDK for .NET (workflows); integrates with broader Microsoft ecosystem | Workflow-first orchestration (workflow as the unit of composition), suitable for chaining agent steps and tool invocations with typed structure. | Documentation emphasizes state and checkpointing to support durable execution. | Designed to support human oversight patterns through workflow control points (details depend on your integration). | Enterprise posture; assumes integration with standard .NET security patterns (secrets, authn/z) and policy at boundaries. | Docs and launch materials position observability as a core requirement for production workflows. | Not explicit in the overview material captured; treat eval harness as external to the framework. | Extensible via .NET composition and adapters; treat tools as services/clients the workflow calls. |
| crewAIInc/crewAI | Python | Python framework + CLI + hosted AMP (deployable “automations”) | Crew (agent team) + Flow (stateful, event-driven workflow). | Flows manage state and execution; agents can maintain memory and enable replay depending on configuration. | Docs enumerate human input / HITL workflows; supports gating and human feedback patterns. | MCP security considerations are documented; hosted AMP includes RBAC and operational controls. | Extensive observability integrations listed (Langfuse, Datadog, MLflow, etc.). | Mentions evaluation integrations (e.g., Patronus AI evaluation) and testing guidance; treat as pluggable. | Tooling system supports custom tools; MCP can be used as tool transport; marketplace/agent repositories in AMP. |
| langchain-ai/langgraph | Python (also JS ecosystem) | Python/JS libraries; deployment via LangSmith Agent Server/SDK | StateGraph / compiled graphs; nodes and edges encode control flow. | Built-in persistence layer via checkpointers; checkpoints stored in threads; enables memory, time travel, and fault tolerance. | Interrupts pause execution, persist state, and resume upon external input. | HITL middleware and policies can gate tool calls; persistence enables audit and rollback. | Streaming and debug stream modes surface execution events; integrates with LangSmith ecosystem. | Evaluation is typically done via LangSmith or external harnesses; docs focus on runtime primitives. | Custom checkpointers supported; nodes are arbitrary code; tool policies can be layered. |
| Significant-Gravitas/AutoGPT | Python | Agent runtime + platform; (historically) CLI and server components | Autonomous task loops; platform-oriented patterns; can be composed into workflows externally. | Uses internal memory/task state abstractions; persistence varies by deployment/configuration. | Often supports human approvals via UI/ops patterns, depending on configuration. | Emphasize governance for autonomy (tool permissions, secrets management, sandboxing). | Varies; can be integrated with external logging/tracing. | Community focus on benchmarks; treat evaluation harnesses as pluggable. | Plugins/integrations are central; agent behaviors can be customized. |
| microsoft/autogen | Python | Python library + Studio (UI) + patterns for multi-agent chat | Conversation-driven (AgentChat / GroupChat) orchestration; routing and delegation are expressed through messaging patterns. | Memory support is documented as a first-class concern; state is often represented as message history plus memory stores. | Human proxy patterns are commonly used; gating depends on how you implement tools and approvals. | Safety posture depends on tool permissions and runtime; framework provides building blocks rather than an opinionated sandbox. | Can be instrumented; Studio provides UI-centric operation. | Evaluation is external; the framework focuses on agent composition. | Extensible via custom agents/tools; integrates with many model backends. |
| KillianLucas/open-interpreter | Python | CLI + Python API; local execution focus | Interactive execution loop where the model proposes code; interpreter executes and returns outputs; optional forced-completion loop. | Conversation/messages can be restored; profiles can capture configuration; persistence is primarily session-level. | Supports explicit user confirmation modes and safe mode options; auto-run allows bypass (use cautiously). | Safe mode options (off/ask/auto) and isolation guidance; offline mode; telemetry disable. | Verbose mode; telemetry controls; output streaming. | Not positioned as a benchmark-first system; evaluation typically done externally. | Supports custom models and execution environments (e.g., Docker, E2B) and configuration profiles. |
| agent0ai/agent-zero | Python (dockerized app) | Web UI + local runtime | UI-driven agent loop with optional multi-agent cooperation; tools invoked as needed. | Docs reference a memory system and summarization, plus knowledge management. | UI provides oversight; autonomy is limited/controlled through user interaction. | Local-first posture; safety depends on runtime permissions; treat web/code tools as governed. | UI provides execution visibility; logs depend on deployment. | Not primarily benchmark-driven; evaluation is external. | Documentation explicitly covers creating custom extensions and connectivity. |
| camel-ai/camel | Python | Python library | Role-based multi-agent dialogues; coordinators can manage agent interactions. | Message history-based state; persistence depends on embedding into a product runtime. | Human oversight patterns are implementation-level. | Framework provides building blocks; governance comes from the embedding application. | Instrumentation depends on host. | Research-focused; evaluation often through experiments rather than standard CI. | Composable agents and task definitions; integrates with model backends. |
| Pythagora-io/gpt-pilot | Python | CLI + iterative project generation | Role-based pipeline that progresses from requirements to implementation; agents collaborate through staged artifacts. | Project artifacts (specs, plan outputs) serve as durable state; local filesystem is the source of truth. | User is kept in the loop; approvals and decision points are integral to its workflow. | Primarily local codegen; risk governed by requiring user decisions and reviewing diffs. | CLI logs; some telemetry is documented, but treat as optional. | Evaluation is external; success measured by generated project correctness. | Extensible through templates and workflow modifications. |
| petabridge/memorizer-v1 | C# (.NET 9/10) | MCP server (HTTP/SSE), Web UI, REST API | Memory graph with typed relationships; no agent orchestration (memory service only). | PostgreSQL + pgvector; full version history with event audit trail; discriminated union events (ContentUpdated, MetadataUpdated, MemoryReverted). | Web UI for manual curation; agents operate autonomously on memory (no permission prompts). | Memory-scoped operations; no shell/file/network access surface; confidence scores for curation. | OpenTelemetry instrumentation with OTLP export; ActivitySource-based spans. | Integration tests; A/B comparison endpoints for embedding strategies (/search/compare). | MCP tool registration via attributes; ADR-documented design decisions; dual embedding strategy for search optimization. |
